* SICP 
** Evaluation Strateies

The whole topic seems to be very confused. Sources put different
meaning in the terminology. It is better to define the term before
you use it in text. This is a glossary following the wiki page
structure but in the context of SICP.

Def.: Determine when to eveluate the arguments of a function.

*** Strict evaluation (Eager)
The most common class in popular languages.
**** Applicative order 
evaluate the arguments and then apply
**** Call by value

**** Call by reference
the function receives an implicit reference to the value rather
then a copy. Think php.

**** Call by sharing
implies that all values are based on objects rather then primitive
types, that values are "boxed". Common in JavaScript, Ruby,
python.

*** Non-strict evaluation
**** Normal Order
Fully expand and then reduce. Same as Call by name.

**** Call by name
Arguments not evaluated before the function is called. If not used
in the function the arg is not evaluated else it is evaluated each
time it appears in the function body. 

**** Lazy evaluation(call by need)
Memoized call by name. If function argument is evaluated it is
stored for subsequent uses. If combined with pure functions
produces same result as Call by name, but saves the cost of
recomputing the argument.

Useful for resursively defining infinite data structures. Data is
only generated as it is consumed and evaluation is terminated
when consumption is complete.

It requires the data to be available and meaningful. In pure fp
languages this is guaranteed from immutability. In procedural
languages it gives us the opportunity to delay calculations until
the data for them becomes available.

Transaction semantics(ts), when combined with lze they compliment,
ts can be used to isolate expressions from tentative changes in
state and lze can delay those same changes until it is time to
commit the transaction. This may be a key component to combining
Object and Functional technilogies.
**** Call by macro expansion

*** Nondeterministic strategies
- Full Beta-reduction
- Call by future

** Evaluation in scheme 
To evaluate a combination:
1. Evaluate the subexpressions of the combination
2. Apply the procedure that is the value of the leftmost
subexpression(the operator) to the arguments that are the values
of the other subexpressions(the operands)

** Numbers
"The characterization of numbers as ``simple data''
is a barefaced bluff"

** Procedures as black-box abstrsctions

Block strucure:
#+BEGIN_SRC scheme
(define (sqrt x)
  (define (good-enough? guess x)
    (< (abs (- (square guess) x)) 0.001))
  (define (improve guess x)
    (average guess (/ x guess)))
  (define (sqrt-iter guess x)
    (if (good-enough? guess x)
      guess
      (sqrt-iter (improve guess x) x)))
  (sqrt-iter 1.0 x))
#+END_SRC

Lexical scoping:
#+BEGIN_SRC scheme
(define (sqrt x)
  (define (good-enough? guess)
    (< (abs (- (square guess) x)) 0.001))
  (define (improve guess)
    (average guess (/ x guess)))
  (define (sqrt-iter guess)
    (if (good-enough? guess)
      guess
      (sqrt-iter (improve guess))))
  (sqrt-iter 1.0))
#+END_SRC

** 1A.2 Procedures and the Processes they generate

A procedure is a pattern for the local evolution of a
computational process. We wnat to be able to reason about the
global process.

*** Linear Recursion and Iteration

We explore the classical factorial function.

Linear recursive process:
$$ n! = n \cdot (n - 1) \cdot (n - 2) \dots 3 \cdot 2 \cdot 1 $$


$$ n! = n (n - 1)! $$

and

$$ n! = 1 $$

Then:

#+BEGIN_SRC scheme
(define (factorial n)
  (if (= n 1)
    1
    (* n (factorial (- n 1)))))
#+END_SRC

Linear iterative process:

We maintain a running product and a counter.
- product <- counter * product
- counter <- counter + 1
And we simultaniously update.

#+BEGIN_SRC scheme
(define (factorial n)
  (iter-factorial 1 1 n))
 
(define (factorial-iter product counter max-count)
  (if (> counter max-count)
    product
    (factorial-iter (* counter product) (+ 1 counter) max-count)))
#+END_SRC

Procedures are distinct from proccesses. Procedures generate
processes. A procedure might look recursive, but generate an
iteretive process. Procedures are about syntax, and processes are
about evolution.

Tail recursive implementations have the property to execute an
iterative process, described by recursive procedure in constant
space.

Recursion process is expansion of deferred operations followed by
contraction of their evaluation.


*** Ackermann's function

A research student to David Hilbert.

The challenge:
Can you come up with something that absolutly has to be done
totally recursive (you can't do it with iteration/loops).

There is a hierarchy of program types.

- Recursively Enumerable functions: for some values of the
arguments they will stop and give an answer, for others they will
go on forever and will never stop repeating the same stack frames.
- Recursive: you have to define recursively
- Primitive recursive: those can be de-recursed

| Type of function       |                                                                                                                                                            |
|------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Undecidable            | ?                                                                                                                                                          |
| Recursively Enumerable | for some values of the arguments they will stop and give an answer, for others they will go on forever and will never stop repeating the same stack frames |
| Recursive              | you have to define recursively                                                                                                                             |
| Primitive recursive    | those can be de-recursed (implemented with iterative for loops)                                                                                            |

#+BEGIN_SRC javascript 
Ackermann(4,0) // -> 13
Ackermann(4,1) // -> 65533
Ackermann(4,2) // -> wait until after the end of the universe ...
#+END_SRC

Will compute in time: 2^{65533} * (time-to-compute Ackermann(4,1))

The number of seconds since the big bang is 2^{59}.
 
This is behaving super exponentially, not $n^{n}$, but
$n^{n^{n^{\dots^{n}}}}$ n to the power of n, n times. We can
never know the answer, but still it is not uncomputable.

*** Tree recursion

Fibonacci numbers: 0,1,1,2,3,5,8,13,21,...

Fib(0) = 0

Fib(1) = 1

Fib(n) = Fib(n - 1) + Fib(n - 2) 


#+BEGIN_SRC scheme
(define (fib n)
  (cond ((= n 0) 0)
        ((= n 1) 1)
        (else (+ (fib (- n 1))
                 (fib (- n 2))))))
#+END_SRC

Use a pair of integers $a$ and $b$ initialized as Fib(1) and
Fib(0), and repeatedly apply the transformations:

a = a + b

b = a
 
#+BEGIN_SRC scheme
(define (fib n)
  (fib-iter 1 0 n))

(define (fib-iter a b count)
  (if (= count 0)
      b
      (fib-iter (+ a b) a (- count 1))))
#+END_SRC

But tree-recursive processes are natural and powerful tool for
operating on hierarhically structured data.

*** Counting Change

How many diff ways we can make change of 1.00 given:
0.50, 0.25, 0.10, 0.05, 0.01

While iterative solution might be harder to find, this problem has
simple a simple solution as a recursive procedure.

Recursively reduce the problem of changing a given amount to the
problem of changing a smaller amount with fewer kinds of coins.


n = f(amount, kinds.drop d) + f(amount - kinds.get d, kinds) 

#+BEGIN_SRC scheme
(define (count-change amount)
  (cc amount 5))

(define (cc amount kinds-of-coins)
  (cond ((= amount 0) 1)
        ((or (< amount 0) (= kinds-of-coins 0)) 0)
        (else (+ (cc amount (- kind-of-coins 1))
                 (cc (- amount (first-denomination kinds-of-coins))
                     kinds-of-coins)))))

(define (denomination kind-of-coins)
  (cond ((= kinds-of-coins 1) 1)
        ((= kinds-of coins 2) 5)
        ((= kinds-of-coins 3) 10)
        ((= kinds-of-coins 4) 25)
        ((= kinds-of-coins 5) 50)))

(count-change 100) ;; -> 292
#+END_SRC




#+BEGIN_SRC scheme

#+END_SRC
** 2A.1
A few programs that have a lot in common with each other.
Make some abstractions that are not easy to make in most languages.

First is the sum:

$$ \sum_{i=a}^{b} i $$

(It has a closed form and it is easy to compute,
but we are not interested in that kind of solution here).

You have a base case and a recursive case

you have an easy case you know the answer to or you have to
reduce it to simpler problem.

The subproblem - add up the integers, one fewer integer, and one fewer
again, and once it is solved add a to it and the result is the answer
to the whole problem. 

#+BEGIN_SRC scheme 
(define (sum-int a b)
  (if (> a b)
    0
    (+ a (sum-int (+ a 1) b))))
#+END_SRC

Recursive function but no tail position
#+BEGIN_SRC javascript
const sumInt = function(a, b) {
    if(a > b) { return 0 }
    return a + sumInt(a+1, b);
};
#+END_SRC

Sum as reduce on a list
#+BEGIN_SRC javascript
const range = function(a, b) {
    return [...Array(b - a + 1).keys()].map(i => i + a);
};

const sumInt = function(a, b) {
    return range(a, b).reduce((acc, x) => acc + x, 0);
};
#+END_SRC


$$ \sum_{i=a}^{b} i^{2} $$

#+BEGIN_SRC scheme 
(define (sum-sq a b)
  (if (> a b)
      0
      (+ (square a)
      (sum-sq (+ 1 a) b))))
#+END_SRC

Now those two programs are almost identicle, the same first clause,
the same predicate, the same consequence, and the alternatives are very
similar too. The only difference is the A and the square of A.

What is similar here has to do with the Sigma notation and not depending
upon what is it adding up.

When you design complex systems and you want to be able to understand them,
it's crucial to divide the things up into as many pieces as you can, each
of which you understand separately.

$$ \sum_{i=a \text{ by } 4}^{b} \frac{1}{i(i + 2)} $$

$$ \frac{1}{1 \cdot 3} + \frac{1}{5 \cdot 7} + \frac{1}{9 \cdot 11} $$

converges to $\frac{\pi}{8}$ 

#+BEGIN_SRC scheme
(define (pi-sum a b)
  (if (> a b)
      0
      (+ (/ 1 (* a (+ a 2)))
         (pi-sum (+ 4 a) b))))
#+END_SRC

When you learn a language you also leearn common patterns of usage.
You learn ideoms, useful things to know at a flash (they are often hard
to think out on your self).

In scheme you can not only know that, but you can also give the knowledge
of that a name. 

The pattern:
#+BEGIN_SRC scheme
;;(define (<name> a b)
;;  (if (> a b)
;;      0
;;      (+ (<term> a)
;;         (<name> (<next> a) b))))
#+END_SRC

Numbers are not special, they are just one kind of data.
You must be able to give all sorts of names to all kinds of data,
like procedures. Many languages allow procedural arguments.

#+BEGIN_SRC scheme
(define (sum term a next b)
  (if (> a b)
      0
      (+ (term a)
         (sum term
              (next a)
              next
              b))))

(sum (lambda (x) (* x x)) 1 (lambda (x) (+ 1 x)) 4)

;; as in the video lecture
(define (sum-int a b)
  (define (identity a) a)
  (sum identity a (+ 1 a) b))

;; helpers diverging from the original
(define (identity x) x)
(define (square x) (* x x))
(define (inc x) (+ 1 x))

(define (sum-sq a b)
  (sum square a inc b))

(define (pi-sum a b)
  (sum (lambda (i) (/ 1 (* i (+ i 2))))
       a
       (lambda (i) (+ 4 i))
       b))
#+END_SRC

With js, but not in tail position
#+BEGIN_SRC javascript 
const sum = function(term, a, next, b) {
    if(a > b) { return 0; }
    return term(a) + sum(term, next(a), next, b);
};

const identity = x => x;
const square = x => x * x;
const inc = x => x + 1;

const sumInt = function(a, b) {
    return sum(identity, a, inc, b);
};

const sumSq = function(a, b) {
    return sum(square, a, inc, b);
};
#+END_SRC

As a reduce on list
#+BEGIN_SRC javascript
const range = function(a, b, next) {
    return [...Array(b - a + 1).keys()].map( x => next(x));
};

const sum = function(term, a, next, b) {
    return range(a, b, next).reduce((acc, x) => {
        return acc + term(x);
    });
};
#+END_SRC

The invention of the procedure that takes a procedural argument, allows you
to compress a lot of these procedures into one thing.

Iterative implementation:
#+BEGIN_SRC scheme
(define (sum term a next)
  (define (iter j ans)
    (if (> j b)
        ans
        (iter (next j)
              (+ (term j) ans))))
  (iter a 0))
#+END_SRC

Iterative implementation for some reasom might be better than the recursive,
but the important thing is that it is different. But the recursive way
allows for decomposition. To independantly change one part of the program
without affecting the other part that was written for some other cases.

** 2A.2
"Computers to make people happy, not people to make computers happy."

Babylonian method for finding square root
#+BEGIN_SRC scheme
(define (sqrt x)
  (define tolerance 0.00001)
  (define (good-enuf? y)
    (> (abs (- (* y y) x)) tolerance))
  (define (improve y)
    (average (/ x y) y))
  (define (try y)
    (if (good-enuf? y)
        y
        (try (improve y))))
   (try 1))
#+END_SRC

Look complicated, it is not obvious by looking at it what it is computing.

If y is a guess for a square root, then what we want is a function f
(this is a means of improvement):

$$ y \xrightarrow{\text{f}} \frac{y + \frac{x}{y}}{2} $$

Such that: 

$$ f(\sqrt{x}) = \sqrt{x} $$

If you subsitute $y$ with $\sqrt{x}$ you get $\sqrt{x}$.
We are looking for a fixed point of the function $f$.

A fixed point is a place which has the property that if you put it into the
function, you get the same value out.
Some functions have the property that you can find their fixed point by
iterating the function.

Following the theorem you can write the square root function and worry
about implemanting fixed-point later.
#+BEGIN_SRC scheme
(define (sqrt x)
  (fixed-point (lambda (y) (average (/ x y) y))
  1))
#+END_SRC

#+BEGIN_SRC scheme
(define (fixed-point f start)
  (define tolerance 0.00001)
  (define (close-enuf? u v)
    (< (abs (- u v)) tolerance))
  (define (iter old new)
    (if (close-enuf? old new)
        new
        (iter new (f new))))
  (iter start (f start)))
#+END_SRC

#+BEGIN_SRC javascript
const average = (...args) => args.reduce((acc, x) => acc+x) / args.length;  

const sqrt = function(x) {
    return fixedPoint( y => average((x/y), y), 1);
};

const closeEnuf = function(u, v, tolerance = 0.00001) {
    return (Math.abs(u - v) < tolerance);
};

const fixedPoint = function(fn, start) {
   function iter(old, cur) {
      if(closeEnuf(old, cur)) {
          return cur;
      }
      return iter(cur, fn(cur));
   }
   return iter(start, fn(start));
};
#+END_SRC

There are other procedures which compute functions whose fixed point would
also be the square root.

$$ y \xrightarrow{\text{g}} \frac{x}{y}} $$

But if x = 2 and you start with 1 it oscillates between 1 and 2, and you
never get any closer to the square root. What you have is a signal
processing system that oscillates and you want to damp put these
oscillations. The average is avariging the last two values of something that
oscillates.

Average-damp is a special procedure that will take a procedure as its arg
and a procedure as its value.
#+BEGIN_SRC scheme
(define (sqrt x)
  (fixed-point
      (average-damp (lambda (y) (/ x y)))
      1))

(define (average-damp
  (lambda (f)
          (lambda (x) (average (f x) x)))))
#+END_SRC

#+BEGIN_SRC javascript
const sqrt = function(x) {
    return fixedPoint(averageDamp( y => x / y), 1);
};

const averageDamp = function(fn) {
    return function(x) {
        return average(fn(x), x);
    };
};

//const averageDamp = fn => x => average(fn(x), x);
#+END_SRC

** 2A.3
"... play with higher-order procedures ..."
"functions map values, procedures compute functions"

Newtons Method:
To find a $y$ such that $f(y) = 0$ 
start with a guess, $y_{0}$

$$ y_{n+1} = y_{n} - \frac{f(y_n)}{f'(y_{n})} $$

You need a function that is to be approximated in the form of $f(y) = 0$.
For example if you need the square root of x you can use $f(y)= x - y^{2}$
which is $x-y^{2} = 0$ or $y = \sqrt{x}$. And now you can use the newton's
method for approximating the value of the equation, which will be the
square root of x.

It is again looking for a fixed point of some procedure. It is more
complicated with those derivatives, but still you want to find the value
of y that will return the same value out of the function.

Top-down approach:
start by math concept, write a name for something, then worriey how to
implement it. Wishful thinking is essential to good engeneering(or cs).
#+BEGIN_SRC scheme
(define (sqrt x)
  (newton (lambda (y) (- x (square y)))))

(define (newton f guess)
  (define df (deriv f))
  (fixed-point
    (lambda (x) (- x (/ (f x) (df x))))
    guess))

(define deriv
  (lambda (f)
    (lambda (x) (/ (- (f (+ x dx))
                      (f x))
                    dx))))

(define dx 0.000001)
#+END_SRC


#+BEGIN_SRC javascript
const dx = 0.000001;

const sqrt = function(x) {
    return newton( y => x - square(y), 1);
};

const newton = function(fn, guess) {
    let df = deriv(fn);
    return fixed-point( x => x - (fn(x) / df(x)), 1);
};

const deriv = function(fn) {
    return function(x) {
        return (fn(x+dx) - fn(x)) / dx;
    };
};
#+END_SRC

Chris Strachey, ligicion one of the grandfathers of cs.
Envented denotational semantics. Great advocate of making procedures first
class citizens:
- to be named by variables
- to be passed as arguments to procedures
- to be returned as values of procedures
- to be incorporated into data structures

** 2B.1 Compound Data

There was an absraction barrier between sqrt and good-enuf.
When we are building things we devorce the part of building things from
the task of implementing the parts. When you are building a complex
system you set a lot of abstraction barriers at a lot of levels.
Now we will do the same for data.

- the system has primitive data
- the system has  means of combination for data(glue to build more
- complicated, compound data from primitive data)
- a methodology for abstraction

Again the key idea is to build the system in layers and set abstraction
barriers that isolate the details at the lower layers from those in the
higher layers(so they can easily be someone elses' concern).

We will build a calculating system:

$$ \frac{1}{2} + \frac{1}{4} = \frac{3}{4},
\frac{3}{4} + \frac{2}{3} = \frac{1}{2} $$

$$ \frac{n_{1}}{d_{1}} + \frac{n_{2}}{d_{2}} = \frac{n_{1}d_{2}+n_{2}d_{1}}{d_{1}d_{2}} $$
$$ \frac{n_{1}}{d_{1}} + \frac{n_{2}}{d_{2}} = \frac{n_{1}n_{2}}{d_{1}d_{2}} $$

Note that the system does not include rational numbers. Will will use the
strategy of wishful thinking.

Lets imagine that we have procedures that act like those:
#+BEGIN_SRC scheme
;; cloud is someting that has n and d
(make-rat n d) -> <cloud> ;; constructor

(numer <cloud>) -> n      ;; selector

(denom <cloud>) -> d      ;; selector
#+END_SRC


#+BEGIN_SRC scheme
(define (+rat x y)
  (make-rat 
    (+ (* (numer x) (denom y))
       (* (numer y) (denom x)))
    (* (denom x) (denom y))))
    
(define (*rat x y)
  (make-rat
    (* (numer x) (numer y))
    (* (denom x) (denom y))))
#+END_SRC

I assume, by wishful thinking that a had a new kind of data
object and ways of creating those objects, a constructor, and
ways to get the parts out with selectors.

You want to carry the numerator and denominator around together
all the time.

The name of this game is that we'd like the programming language
to express the concepts that we have in our heads, like rational
numbers are things that you can add and then take that result and
multiply them.

#+BEGIN_SRC scheme
(*rat (+rat x y) (+rat z w))
#+END_SRC



Now let's look at the other problem. We need a glue for data
objects that allows us to put things together.

- list stucture
- pairs
- cons, operator
- box and pointer notaion

#+BEGIN_SRC scheme
(cons x y) ;; constructs a pair with x first and y second part

(car p)    ;; selects the first part of the pair

(cdr p)    ;; selects the second part of the pair
#+END_SRC


NOTE: The names come from the instructions set on the IBM 704.
- cons cells:
- car: constents of address register, head
- cdr: contents of decrement register, tail

#+BEGIN_SRC scheme
(define (make-rat n d)
  (cons n d))

(define (numer x)
  (car x))

(define (denom x)
  (cdr x))
#+END_SRC


#+BEGIN_SRC scheme
(define A (make-rat 1 2))

(define B (make-rat 1 4))

(define ans (+rat A B))

(numer ans) ;; -> 6
(demon ans) ;; -> 8
#+END_SRC

We need to reduce it to lowest terms. Lets redefine make-rat:

#+BEGIN_SRC scheme
(define (make-rat n d)
  (let ((g (gcd n d)))
    (cons (/ n g)
          (/ d g))))
#+END_SRC

Now we have a full system for rational numbers.
the abstruction barrier is between the operations +rat, *rat, -rat
and the pairs, between the use and the representation.

Use: +rat, *rat, -rat  

Abstraction layer: make-rat, numer, denom  

Representation: pairs  

Data abstruction: a programming methodology of setting up data
objects by postulating constructors and selectors to isolate use
from representation.

But why are we doing all of this? We can write it with less code.
#+BEGIN_SRC scheme
(define (+rat x y)
  (cons (+ (* (car x) (cdr y))
           (* (car y) (cdr x)))
        (* (cdr x) (cdr y))))
#+END_SRC

The most important principal in sorcery is if you know the name of
the spirit you get control over it. In cs if you have the name of
the thing you get control over it. If we write it this way we lose
control. In system like that you don't have the idea about
rational number as a conceptual entity.

But what is the advantage of isolation?
You might want to have alternative representations:
For example when you make rational number you may just cons it.

#+BEGIN_SRC scheme
(define (make-rat n d)
  (cons n d))

(define (number x)
  (let ((g (gcd (car x) (cdr x))))
    (/ (car x) g)))

(define (numer x)
  (let ((g (gcd (car x) (cdr x))))
    (/ (cdr x) g)))
#+END_SRC

But there are 3 ways to do it. Which one is better?

In general the way you'd like to retain flexibility is to never
make up our mind about anything until you are forced to do it.
The problem is, there is a very narrow line between deferring
decisions and outright procrastination. You want to make progress,
but also never be bound by the consequences of your decisions.
Data abstruction is one way of doing this. We used wishful
thinking. We gave a name to the decision.
We gave a name to the decision of how we are going to do it, and
then continuing as if we made the decision.

NOTE: let is a way of setting up a context where you can make
definitions. But those definitions are local to this context.

** 2B.2

Points in a plane.

#+BEGIN_SRC scheme
;; representing vectors in a plane
(define (make-vector x x)
  (cons x y))

(define (xcor p) (car p))

(define (ycor p) (cdr p))

;; line segments
(define (make-seg p q)
  (cons p q))

(define (seg-start s) (car s))

(define (seg-end s) (cdr s))

(define (mid-point s)
  (let ((a (seg-start s))
        (b (seg-end s)))
    (make-vector
      (average (xcor a) (xcor b))
      (average (ycor a) (ycor b)))))

(define (seg-length s)
  (let
      ((dx (- (xcor (seg-end s))
              (xcor (seg-start s))))
       (dy (- (ycor (seg-end s))
              (ycor (seg-start s)))))
    (sqrt (+ (square dx)
             (square dy)))))
             
(define (+vect v1 v2)
  (make-vector
    (+ (xcor v1) (xcor v2))
    (+ (ycor v1) (ycor v2))))
    
(define (scale s v)
  (make-vector (* s (xcor v))
               (* s (ycor v))))
#+END_SRC

line -> point -> number

Closure - the means of combination in your system are such that
when you put things together using them, like we make a pair,
you can then put those together with the same means of
combination. So you can have not only a pair of numbers, but a
pair of pairs.

For example in Fortran you have arrays, but you can not put array
in an array.

Are the things you make closed under that means of combination?
Pairs would not be that interesting if all you can do is a pair
of numbers.

Remember naming things gives us control over complexity.

Q: but what about 3d points?
A: Once you have 2 things you have as many things as you want.

** 2B.3
"existential crisis"

You can build the cons primitive and car and cdr from nothing.

#+BEGIN_SRC scheme
(define (cons a b)
  (lambda (pick)
    (cond ((= pick 1) a)
          ((= pick 2) b))))

(define (car x) (x 1))

(define (cdr x) (x 2))
#+END_SRC

#+BEGIN_SRC javascript
const cons = function(a, b) {
    return function(pick) {
        if(pick === 1) { return a };
        if(pick === 2) { return b };
    };
};

const car = x => x(1);
const cdr = x => x(2);
#+END_SRC

The point is it could work this way and it wouldn't make any
difference to the system at all.
We are going to blur the line between data and procedure. 

Procedures can be objects. We can write it this way:
#+BEGIN_SRC scheme
(define make-vector cons)
(define xcor car)
(define ycor cdr)

(define make-segment cons)
(define seg-start car)
(define seg-end cdr)

(make-seg (make-vector 2 3)
          (make-vector 5 1))
#+END_SRC

Closures are the thing that allows us to start building up
complexity, that didn't trap us in pairs.

The set of data objecys in Lisp is closed under the operation
of forming pairs. (Like in Fortarn you can put numbers and chars,
in an array, but not make array of arrays)

** 3A.1 Henderson Escher Example

There are many ways to represent sequances with pairs.
Lisp has a particular convention for representing a sequance of
things as essentially a chain of pairs. And that is called a list.

#+BEGIN_SRC scheme
;; [1, pointer-next] -> [2, pointer-next] -> [3, nil]

(cons 1
  (cons 2)
    (cons 3
      (cons 4 nil)))

;; a short hand for cons cons ...
(define 1-to-4 (list 1 2 3 4))

(car 1-to-4)             ;; -> 1
(car (cdr 1-to-4))       ;; -> 2
(car (cdr (cdr 1-to-4))) ;; -> 3

(scale-list 1-to-4)

;; cdr-ing a down a list
(define (scale-list s l)
  (if (null? l)
      null
      (cons (* (car l) s)
            (scale-list s (cdr l)))))

(scale-list 10 '(1 2 3 4))

;; but you should be using higher order functions
(define (map p l)
  (if (null? l)
      null
      (cons (p (car l))
            (map p (cdr l)))))
            
(define (for-each proc list)
  (cond ((null? list) "done")
        (else (proc (car list))
              (for-each proc
                        (cdr list)))))

(define (scale-list s l)
  (map (lambda (item) (* item s))
       l))
#+END_SRC

#+BEGIN_SRC javascript 
const map = function(fn, xs) {
    if(null === xs) { return null };
    return cons( fn(car(xs)), map(fn, (cdr xs)) );
};

const forEach = function(proc, list) {
    if(null === list) { return "done"; }
    proc(car(list));
    return forEach(proc, cdr(list)); 
};
#+END_SRC

** 3A.2

Meta-linguistic abstraction: tackling complexity in engineering
design is to build a suitable powerful language.

When you think about a language yu think in the terms of
- Primitives
- Means of combination
- Means of abstruction

You take those bigger things that you build and put black boxes
around them and use them and use them as elements in building
something even more complicated.

The basic is a rectangle. It is specified by an origin + horiz +
vert verteces.

#+BEGIN_SRC scheme
(define (make-rect) ())
(define (horiz) ())
(define (vert) ())
(define (origin) ())

#+END_SRC

There is a transformation that maps from the basis square to the
rectangle.

#+BEGIN_SRC scheme
(define (coord-map rect)
 (lambda (point)
   (+vert
     (+vert (scale (xcor point)
                   (horiz rect))
            (scale (ycor point)
                   (vert rect)))
     (origin rect))))

(define (make-picture seglist)
  (lambda (rect)
    (for-each
      (lambda (s)
        (drawline
          ((coord-map rect) (seg-start s))
          ((coord-map rect) (seg-end s))))
      seglist)))
#+END_SRC

** 3A.3

That is the part about the picture language. You have a rectangle
box and you have to fit/fill images inside, which means
transforming the image by squishing and stretching. Sorry but this
part is boring.

** 3B.1 Symbolic Differentiation

In order to make a system more robust, it has to be insensitive to
small changes, that is a small change in the problem should lead
to only a small change in the solution. Instead of solving a
particular problem at every level of decomposition of the problem
at subproblems, where you solve the class of problems, which are a
neighborhood of the particular problem you are tring to solve.
The way you do that is by introducing a language at that level of
detail in which the solutions to that class of problems is
representable in the language. Therefore when you change makes
small changes to the problem ou are tring to solve, you generally
have to make only small local changes to the solution you've
constructed, because at the level of detail you ara working,
there is a language where you can express the various solutions
to alternate problems of the same type. That is the begging of
the most important idea that makes cs more powerful then most of
the other kinds of engineering. So far we've seen how to use
embedding of languages. This power comes partly from higher order
procedures. However now we are going to blur the lines between
data and procedures(very badly this time). Can we make programs
that manipulate mathematical expressions (like the rules about
derivatives).

Robustness requres insensitivity to small  changes.
Where you should solve at:
- Level of decomposition
- Class of neighourhood problems
  
Solution:
Make a language that represents the solutions of that class of
problems. Embeding languages makes cs the most powerful kind of
engeneering.

#+BEGIN_SRC scheme
(define (derive f)
  (lambda (x)
    (/ (- (f (+ x dx))
          (f x))
       dx)))
(define dx 0.00001)
#+END_SRC

The porblem:
Why derivatives are easy to express, while their opposites the
integrals are hard? Consider:

$$ \frac{d(u+v)}{dx} = \frac{du}{dx} + \frac{dv}{dx} $$
$$ \frac{d(uv)}{dx} = u\frac{dv}{dx} + v\frac{du}{dx} $$

Going to the right is a reduction, you construct from a simpler
problem (easy for recursion).

While going to the left, trying to produce integrals:
- more than one rule mathches (sums)
- expressioin become larger (termination is not guarantied)

Making dispatch on the type of the expression (absolutly
essential in building languages).

Constant, Sum rule, Product rule:
#+BEGIN_SRC scheme

(define (deriv exp var)
  (cond ((constant? exp var) 0)
        ((same-var? exp var) 1)
        ((sum? exp)
         (make-sum (deriv (a1 exp) var)
                   (deriv (a2 exp) var)))
        ((product? exp)
         (make-sum (make-product (m1 exp)
                        (deriv (m2 exp) var))
          (make-product (m2 exp)
                        (deriv (m1 exp) var))))))

(define (atom? x)
  (and (not (null? x))
       (not (pair? x))))

(define (constant? exp var)
  (and (atom? exp)
       (not (eq? exp var))))

(define (same-var? exp var)
  (and (atom? exp)
       (eq? exp var)))

(define (sum? exp)
  (and (not (atom? exp))
       (eq? (car exp) '+)))

(define (make-sum a1 a2)
  (list '+ a1 a2))

(define a1 cadr)

(define a2 caddr)

(define (product? exp)
  (and (not (atom? exp))
       (eq? (car exp) '*)))

(define (make-product m1 m2)
  (list '* m1 m2))

(define m1 cadr)

(define m2 caddr)

#+END_SRC

I want to represent sums, products, differences and quotients,
why not use the same language as I am writing my program in. 

#+BEGIN_SRC scheme
(+ (* a (* x x))
   (* b x)
   c)
#+END_SRC

In list structures every one of these objects has the property
that I know where the car is (the operator). It is already parsed.

- Car is the operator
- Cdrs are the operands (succesive car cdr)

Ambiguity in natural language:
- "Say your name!". 
- "Say: 'your name'!"

Resolved with quotation.

But quotation may be the prototypical referentialy opaque context.

PN: as the ancient greeks had to develop math mostly through
geometry, because they did not have a suitable language for
alegbra ($\sqrt{2}$ is a famous instance of this problem).

** 3B.2 Symbolic Differentiation Continued

The form of the proccess is expanded from the local rules that
you see in the procedure. The procedure represents a set of local
rules for the exapnsion of this process. Here the process left
behind some stuff, which is the answer, and it was constructed by
the walk it takes of the tree structure, which is the expresion.

The same problem as with the rational numbers, the answer was not
simplified.

- Derivative rules: Sum rule, Power rule
- Abstraction Barrier: constant? same-var? sum? make-sum?
- Representation of alg. exp.: list structure

Having this barrier helps me to arbitrarily change this
representation without changing the rules that I have written in
terms of that representation.

Many constructioins seem redundant:
- exp + 0 = exp
- exp * 1 = exp

#+BEGIN_SRC scheme
(define (make-sum a1 a2)
  (cond ((and (number? a1)
              (number? a2))
         (+ a1 a2))
        ((and (number? a1) (= a1 0)) a2)
        ((and (number? a2) (= a2 0)) a1)
        (else (list '+ a1 a2))))

(define (make-product m1 m2)
  (cond ((and (number? m1)
              (number? m2))
         (* m1 m2))
        ((and (number? m1) (= m1 1)) m2)
        ((and (number? m2) (= m2 1)) m1)
        ((and (number? m1) (= m1 0)) 0)
        ((and (number? m2) (= m2 0)) 0)
        (else (list '* m1 m2))))
#+END_SRC


** 4A.1 Pattern-matching: Rule-based Substitution

Why we should have to transfer these rules into the language of
the computer? 

It was a very stylized program:
- a conditional
- a dispatch on the type of the expression
- as observed by the rules

Is there a more clear way to write this program?

What is a Rule? Rules have parts:

$$\frac{dvu}{dx} = u\frac{dv}{dx} + v\frac{du}{dx}$$

- left hand side: is compared with the expression we try to take
the derivative of
- right hand side: is the replacement of that expression

All rules are something like this:
- Pattern: something that matches $\frac{dvu}{dx}$
- Skeleton: something you substitute into in order to make get a
new expresion $u\frac{dv}{dx} + v\frac{du}{dx}$

That means a pattern is matched against the expression (which is
the source expresion) and the result  of the application of the
rule is to produce a new expression (a target) by instantiatio of
a skeleon.

Rules(forms a graph 1->2->4 1->3->4):
- 1. Pattern, 2. Skeleton, 3. Expression Source, 4. Expression Target
- (1->2): Rule, (1->3): Match, (3->4): undefined, (2->4): Instantiation 

TODO: add a graphic with both schemas from beginning and end of
lecture

We want to build a language and a means of interpreting that
language, executing that language, a language that allows to
directly express those rules.

Instead of bringing the rules to the  level of the computer, by
writing a program that is those rules, we are going to bring the
computer to the level of us, by writing a way by which the
computer can understand a rules of this sort.

We are trying to write a solution to a class of problems, rather
then a particular one.

We would like to encapsulate all of the things that are common to
both of those programs: the idea of matching, instantiation, the
controll structure, separatly from the rules themselves.

#+BEGIN_SRC scheme

(define deriv-rules
  '(
    ( (dd (?c c) (? v))     0)
    ( (dd (?v v) (? v))     1)
    ( (dd (?v u) (? v))     0)

    ( (dd (* (? x1) (? x2)) (? v))
      (+ (dd (: x1) (: v))
         (dd (: x2) (: v)))  )
    ;; ...
    ))
#+END_SRC

Rule 1:
- the derivative of a constant $c$ with respect to a variable $v$ 
- And on the rigth-hand side we get: 0

Rule 4:
- the derivative of the sum of exp. $x1$ and exp. $x2$ with respect
to a variable $v$
- 1

- Pattern variables: begin with ?
- Substitution object: is : for evaluation
- left-hand side is the pattern
- right hand-side is the skeleton

Patterns to match:
- foo matches to foo
- (f a b) matches a list with elements f, a, b
- (? x) matches any, call at x
- (?c x) matches a constant, called x
- (?v x) matches a variable, called x

Skeletons for instantiation:
- foo instantiates foo
- (f a b) instantiates list of the results of instantiating f, a, b
- (: x) instantiates the value of x


We are going to write a general purpose simplifier:
#+BEGIN_SRC scheme
(define dsimp (simplifier deriv-rules))

(dsimp '(dd (+ x y) x))
;; -> (+ 1 0)
#+END_SRC

Once we are done with calculus rules we may add algebraic
manipulation rules.


Rule 1:
- any operator applied to a constant e1 and a constant e2 is the
result of evaluating that operator on the constants

#+BEGIN_SRC scheme
(define algebra-rules
  '(
    ( ((? op) (?c e1) (?c e2))
      (: (op e1 e2)))

    ( ((? op) (? e1) (?c e2))
       ((: op) (: e2) (: e1)))

    ( (+ 0 (? e)) (: e))

    ( (* 1 (? e)) (: e))

    ( (* 0 (? e)) 0)
    ;; ...
))
#+END_SRC




# template
#+BEGIN_SRC scheme

#+END_SRC
