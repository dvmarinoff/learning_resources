* Limits and Continuity

** ex.1: Limit

\lim_{x\to 3} f(x) = 4

\lim_{x \to 3-} f(x) = 4

\lim_{x \to 3+} f(x) = 4

- the limit of f of x as x approaches 3 is 4
- the limit as we approach from the left is 4
- the limit as we aproach from the right is 4

** ex.2: Right and Left

\lim_{x\to 3-} f(x) = -4

\lim_{x\to 3+} f(x) = 1

- the function is discontinuos at x = 3,
- we have 2 limits from right and left, but
- the limit at x\to 3 does not exist

- the value of a function is not the same as the limit of the function
- we predict the limit by approximating infinitly close to the value,
but the value may be undefined, and the function can still have a limit,
- but if the value is infinity, we are infinitly approximating infinity
and in this case the limit does not exist from that direction


** ex.3: Continuity

*** Over a point
f is continuos when x=a if and only if

\lim_{x\to a} f(x) = f(a)

*** Over an interval

f is cont. over (a,b) if and only if
f is cont. over every point in that interval

f is cont. over [a,b] if and only if

\lim_{x\to a+} f(x) = f(a) and \lim_{x\to b-} f(x) = f(b) 

** Properties of Limits

\lim_{x\to a} f(x) = L   \lim_{x\to a} g(x) = M

\lim_{x\to a}( f(x) + g(x) ) = L + M     | Sum

\lim_{x\to a} ( f(x) - g(x) ) = L - M    |

\lim_{x\to a} ( f(x) * g(x) ) = L * M    | Product

\lim_{x\to a} ( f(x) / g(x) ) = L / M    | Difference

\lim_{x\to a} f(g(x)) = lim f( lim g(a) )| Composition



** Limits by substitution, factoring and rationalizing

ex.4:

f(x) = x^2 + x - 6 / x - 2 = (x + 3)(x - 2) / (x - 2) = x + 3 , x != 2

f(x) { x + 3     , x != 2
     { undefined , x = 2

\lim_{x\to 2} f(x) = ?

ex.5:

\lim_{x\to -2} x + 1/ sqrt(x + 5) - 2 = ?    | 0/0

g(x) = x + 1/ sqrt{x + 5} - 2 =

= (x + 1 / sqrt{x + 5} - 2) * (sqrt{x + 5} + 2 / sqrt{x + 5} + 2) =

= (x + 1)(sqrt{x + 5} + 2) / x + 5 - 4 = sqrt{x + 5} + 2 , x !0= -1

f(x) = sqrt{x + 5} + 2
f(x) = g(x) for all x != 1

\lim_{x\to -1} g(x) = 4


(a + b)(a - b) = a^{2} - b^{2}


** Limits of trigonometric functions

ex.6:

\lim_{x\to \pi} sin(x) = ? = sin(\pi) = 0

sin and cos are defined for all real numbers and are continuos
over thier entire domain (tan and cot are also continuous), and
thier limit will be the value of the function at that point


\lim_{x\to \pi} tan(x) = lim sin(x)/cos(x) = 0 / -1 = 0

\lim_{x\to \pi} cot(x) = lim cos(x)/sin(x) =

sin \pi = sin(\pi/2 + \pi/2) = cos \pi/2 = 0
sin(\pi) = 0
cos(0) = 1
cos(\pi) = -1
cos(\pi/2) = 0


Note: 0/0 is undetermined form -> the limit may still exist


*** Squeeze theorem (Sandwich theorem)

Calories:
Imran <= Diya <= Sal

Tuesday: 1500 <= x <= 1500    -> x = 1500

The math vertion for functions

f(x) <= g(x) <= h(x)

\lim_{x\to a} f(x) = L    \lim_{x\to a} h(x) = L

-> \lim_{x\to a} g(x) = L

*** \lim_{x\to 0} sin(x)/x



* Derivatives

** Intro to derivatives

1) The 'instantanious' rate of change

2) Derivatives arBG
e about looking at tiny changes to some quontity
and how that relates to a resulting tiny change in another quontity

3) derivative is equal to the slope of a line tangent to the graph
at a single point

- avarage rate of change formula, slope

the slope of a curve is always changing at each point

f(b) - f(a) / b - a

- derivative

f'(x) = \frac{df}{dx} = \lim_{x\to\0} = \frac{f(x+h) - f(x)}{h}

#+STARTUP: latexpreview
\frac{f(b) - f(a)}{b - a}
#+STARTUP: nolatexpreview

- differentiability - does the function have a defined derivative at a point

if f is differentiable at x = a, then f is continuous x = a

f is not differebtiable if:
1) if f not continuous at x = a, then f is not differentiable
2) if f have vertical tangent at x= a f is not differentiable at x = 0
3) 'sharp turn' - as we approach the point from left or right slope of tangent is different

f(x) = abs(x) is not differentiable at the point of the 'sharp turn'

- tangent line equation

to get slope of the tangent line at the point a (derivative):

\lim_{h\to 0} \frac{f(a + h) - f(a)}{h}

to get tangent line equation (using the derivative):

f(x) = x^3
slope = 3
point = (-1,-1)

3 = y - (-1) / x - (-1)
y = 3x + 2

for
y = mx + b
where m is the slope and b is the y intercept
or

(y-y1) / (x - x1) = b

- Local linearity

The concept:
if we zoom enough on a non-linear function it will
start looking as a linear function

[[./img/local_linearity.jpg]]

Try that on:
y = x^1000
and zoom at the 'sharp turn', it will bein to look linear

Find approximation of the sqrt 4.36 without calculator?

$ \sqrt{4.36} = ? $

$ \sqrt{4} = 2 $

f(4) = 2
f(4.36) = ?

$ f(x) = \sqrt{x} = x^1/2 $

If we find the equation for the tangent line at f(4) we may approximate the f(4.36):

L(x) = f(a) + f'(a)*(x-a)

L(x) = f(4) + f'(4)*(x-4)

From Power rule:
f'(x) = 1/2 * x^-1/2
f'(4) = 1/4

L(4.36) = f(4) + f'(4)*(4.36 - 4)
= 2 + 1/4 * 0.36
= 2 + 0.09
= 2.09

$ 2.09^2 = 4,3681 $

$ \sqrt{4.36} = 2.088061 $

** Derivatives rules

*** Basic rules

1) Constant rule

f(x) = k
-> f'(x) 0

2) Constant multiple rule

f(x) = k g(x)
-> f'(x) = k g'(x)

3) Sum rule
- of two functions

f(x) = g(x) + j(x)
-> f'(x) = g'(x) + j'(x)

*** Power rule

d/dx [x^n] = nx^n-1 , n != 0

NOTE:
derivative of x is 1x^0 = 1

*** Derivative of sin and cos

d/dx sin = cos

d/dx cos = -sin

*** Derivative of e^x and ln(x)

d/dx [sin x] = cos x
d/dx [cos x] = -sin x
d/dx [tan x] = 1/cos^2(x) = sec^2(x)

d/dx [e^x] = e^x

slope of the tangent line at any point on e^x equals the value of e^x

d/dx [ln x] = 1/x = x^-1

fills the gap in the power rule

d/dx [ln(4x)] = 4/4x

*** Product rule


d/dx[f(x) * g(x)] = f'(x)*g(x) + f(x)*g'(x)

*** Quotent rule

f(x) = u(x)/v(x)

f'(x) = u'(x)*v(x) - u(x)*v'(x) / [v(x)]^2

*** Chain Rule

the most common one, any time your function
can be used as composition of more than one funtions

h(x) = (sin x)^2 = sin^2(x)

h'(x) = dh/dx = 2sin(x) * cos(x)

from

a^2 = 2a
sin(x) = cos(x)

d/dx [f(g(x))] = f'(g(x)) * g'(x)

d/dx [f(g(h(x)))] = f'( g(h(x)) ) * g'(x) * h'(x)

Ex.:

d/dx [sin(ln(x^2))] = ?

f(x) = sin(x)  f'(x) = cos(x)
g(x) = ln(x)   g'(x) = 1/x
h(x) = x^2     h'(x) = 2x

cos(ln(x^2)) * 1/x^2 * 2x
= 2/x * cos(ln(x^2))

*** Log differentiation

d/dx [ln x] = 1/x

d/dx [log_a(x)] = 1 / (ln a) * x

Remember that:

log_a(b) = log_d(a) / log_d(b)

d/dx [log_4(x)] = 1 / (ln 4) * x


Ex:

d/dx [sin(ln(x^2))] = ?

f(x) = sin(x)
g(x) = ln(x)
h(x) = x^2

= cos(ln(x^2) * 1/x * 2x
= 2 * cos(ln(x^2))

*** Trigonometric function differentiation

d/dx[tan(x)] = d/dx[sin(x)/cos(x)] = 1/cos^2(x) = sec^2(x)

d/dx[cot(x)] = d/dx[cos(x)/six(x)] = -1/sin^2(x) = -csc^2(x)

d/dx[sec(x)] = d/dx[1/cos(x)] = sin(x)/cos^2(x)

d/dx[csc(x)] = d/dx[1/sin(x)] = -cos(x)/sin^2(x)

*** Second derivatives

*** Implicit differentiation


*** Parametric functions



* Existence theorems

if f(x) is continuous over the closed interval [a,b]

*** Intermediate Value Theorem

'There exist a c that lies on L'

Suppose f is a function continuous at every point
of the interval [a,b]:

- f will take on every value between
 f(a) and f(b) over the interval

- For any L between the value f(a) and f(b),
 there exists a number c in [a,b] for which f(c) = L

*** Extream Value Theorem

'There exist values where the function takes a maximum and a minimum'

f cont. over [a,b] -> Exists absolute maximum and
absolute minimum value of f

*** Mean Value Theorem

'If also differeniable over the open interval (a,b)
There exists a pint c where the derivative of f(x)
(slope of the tangent line at that point) is the same
as the avarage rate of change'


NOTE: Differentiability implies continuity

[[./img/existence_theorems_intro.jpg]]


* Using Derivatives to Analyze Functions

** L'Hopital's rule

Using derivatives to take limits
Useful in special case of undetermined form:

{0}/{0}

\infty/\infty

-\infty/\infty



\lim_{x\to a} f(x) = 0

and

\lim_{x\to a} g(x) = 0

and

\lim_{x\to a} \frac{f'(x)}{g'(x)} = L

Then:

\lim_{x\to a} \frac{f(x)}{g(x)} = L

[[./img/l'hopital's_rule.jpg]]

** Minimun and Maximum

f(c) is a relative maximum
if f(c) >= f(x)
for All x member of (c - h, c + h) for h > 0

f(d) is a relative minimum
if f(d) <= f(x)
for All x member of (d - h, d + h) for h > 0

** Analyzing a function with its derivative

When f'(x) is below the x axis f(x) is decreasing

Example:

f(x) = x^3 - 12x + 2
f'(x) = 3x^2 -12

3x^2 - 12 = 0
x^2 = 4
->
x = 2, x = -2

f'(2) = 0, f'(-2) = 0

so f(x) has critical points at x = 2 and x = -2

[[./img/analyzing_function_with_its_derivative.jpg]]

** Critical points

non endpoint, min or max at x = a ->
f'(a) = 0
f'(a) = undefined

but not when the function is also undefined at that point


Example: Finding critical points of a function

f(x) = xe^(-2x^2)

From product and chain rule:

f'(x) = d/dx[x]e^(-2x^2) + d/dx[e^(-2x^2)]x

= 1e^(-2x^2) + e^(-2x^2)*(-4x)*x

= e^(-2x^2) * (1 - 4x^2)

we can get it equal to 0 only when (1 - 4x^2) is equal to 0

1 - 4x^2 = 0
x^2 = 1/4
x = 1/2, x = -1/2

critical points are at 1/2 and -1/2



Example: Finding decreasing interval

f(x) = x^6 - 3x^5

f'(x) = 6x^5 - 15x^4

6x^5 - 15x^4 < 0

3x^4(2x - 5) < 0

(3x^4 < 0 AND 2x - 5 > 0) OR (3x^4 > 0 AND 2x - 5 < 0)

x^4 < 0 will never be less than 0 and x != 0

2x - 5 < 0

x < 5/2

-> the decreasing interval is

x < 0 OR x 0 > x < 5/2



Example: Finding inceasing interval

g'(x) = x^2 / (x - 2)^3


x^2 / (x - 2)^3 > 0

(x - 2)^3 > 0

x > 2

(2, \inf)


*** Practice:
Find critical points of:
01. g(x) = x^3 + x^2 + x
g'(x) = 3x^2 + 2x + 1
3x^2 + 2x + 1 = 0
3x(x + 2/3) = -1

It is never undefined or 0
No critical points

02. h(x) = sqrt(x^2 + 4)
h'(x) = 1/2(x^2 + 4)^-1/2 * 2x

x = 0 undifined

03. h(x) = e^(2x-6) - e
h'(x) = e^(2x-6) * d/dx[2x - 6]
= 2 * e^(2x-6)

2e^(2x-6) = 0 has no solutions and is never undefined
No critical points

04. h(x) = 4x^2 / x^2 - 1
h'(x) = (8x * (x^2 - 1)) - (2x * (4x^2)) / (x^2 -1)^2
= 8x^3 - 8x - 8x^3 / x^4 + 1
= -8x / x^4 + 1

x = 0 is undefined

05. f(x) = 2x^3 - 9x^2 + 12x
f'(x) = 6x^2 - 18x + 12
6x^2 - 18x + 12 = 0
6x(x - 3 + 12/6x) = 0
or
6(x - 1)(x - 2) = 0

x = 1 and x = 2

06. h(x) = e^(2x) / x - 3
h'(x) = 2e^(2x) * (x - 3) - e^(2x) / (x - 3)^2
= -7e^(2x) + 2x*e^2x = e^(2x)*(2x - 7)

x = 7/2 is equal to 0
x = -3 is undefind, but also h(x) is undefined so it is not a critical point

07.

** Finding relative extrema

Relative maximum
When does g' go from g'>0 to g'<0 (from positive to negative value)

Example: Find revalive extrema of g(x) = x^4 - x^5
g'(x) = 0 when

4x^3 - 5x^4 = 0
x^3(4 - 5x) = 0

x^3 = 0, x = 4/5 are critical points

g'(x) = undefined when
never

Analyze values (graph) of the derivative:

| interval   | value          | direction |
|------------+----------------+-----------|
| (-\inf, 0) | g'(-1) = -9    | dec       |
| (0, 1)     | g'(1/2) = 3/16 | inc       |
| (1, \inf)  | g'(1) = -1     | dec       |

Note:
it may be the case that derivative is 0, but that critical
point is not an extremum. For example when the value (graph)
is positive goes to 0 then back to being positive

|graph            | local exremum |
|-----------------+---------------|
| pos -> 0 -> neg | maximum       |
| neg -> 0 -> pos | minimum       |
| pos -> 0 -> pos | false         |
| neg -> 0 -> neg | false         |


[[./img/critical_point_intro.jpg]]

** Concavity

upwards concavity
downwards concavity

[[./img/concavity_intro.jpg]]

** Inflection points

An inflection point is a point on a graph where the slope goes from
decreasing to increasing, or from increasing to decreasing.
Point where we change concavity.

You can get them from first derivatives:

When f'(x) crosses the x-axis it is a min or max point for f(x)
When f'(x) reaches a min or max point it is an inflection point for f(x)

You can get them from second derivatives:

When f''(x) crosses the x-axis

| f''                             | f'                                 | f                                    |
|---------------------------------+------------------------------------+--------------------------------------|
| positive +                      | increasing up                      | concave up                           |
| negative -                      | decreasing down                    | concave down                         |
| crossing x-axis (changing sign) | extremum point (changes direction) | inflection point (changes concavity) |

*** Second derivative test

If you have:
h(8) = 5
h'(8) = 0
h''(8) = -4

Is (8,5) on f(x) a relative minimum, maximum point or
there is not enough information?

[[./img/second_derivative_test.jpg]]


** Finding Inflection points and Analyzing Concavity

Example:
Let g(x) = -x^4 +6x^2 - 2x - 3.
Find intervals where g(x) is concave upwards or downwards?

g'(x) = -4x^3 + 12x - 2

g''(x) = -12x^2 + 12

-12x^2 + 12 = 0
x^2 = 1
x = 1
x = -1

g''(-2) = -36   (-\inf, -1)   down

g''(0) = 12     (-1, 1)       up

g''(2) = -36    (1, \inf)     down



Example:
Let g(x) = 1/4x^4 - 4x^3 + 24x^2.
For what values of x does the graph of g have an inflection point?

g'(x) = 1x^3 - 12x^2 + 48x

g''(x) = 3x^2 - 24x + 48

3x^2 - 24x + 48 = 0
x = 4

But
f''(0) = 48    (0, 4)    pos

f''(4) = 0     0         0

f''(10) = 108  (4, 108)  pos

->

There is no inflection point

NOTE:
Remember to check for candidates
Remember that there might be inflection point on undefined values
Remember to check that f''(x) is actually crossing the x-axis

** Graphical Relationship between a function and its derivatives

*** Relationship between f and f'

[[./img/graphical_relation_f_f'.jpg]]

*** Relationship between f and anti-derivative

Anti-derivative

The Anti-derivative of a function is a function whose derivative is that
function

anti-derivative of f(x) is F(x)

d/dx F(x) = F'(x) = f(x)

[[./img/graphical_relation_f_F.jpg]]



* Accumulation and Rienmann Sums

** Definite Integral

one of the pilars of calcluus(along indefinite integrals and derivatives)

it os about an area under a graph represented as sum of infinitly small
parts betweem point a (lower bound) and point b(upper bound).

\int_{a}^{b} x^2 dx

[[./definite_integral.jpg]]

** Riemann approximation

[[./riemann_approximation.jpg]]


** Summation Notation

1 + 2 + 3 + 4 + ...  + 9 + 10

How to express it more concise?

\sum_{i=1}^{10} i

\sum_{i=0}^{50} \pi i^2 = \pi 0^2 + \pi 1^2 ... + \pi 49^2 + \pi 50^2



Example:
Consider 2 + 5 + 8 + 11:

\sum_{n=1}^{4} (3n - 1) = 3(1)-1 + 3(2)-1 + 3(3)-1 + 3(4)-1

\sum_{n=0}^{3} (2 + 3n) = 2+3(0) + 2+(3*1) + 2+(3*2) + 2+(3*3)



Example:
Consider

\sum_{n=1}^{4} \frac{k}{n+1} = k/2 + k/3 + k/4 + k/5

[[./riemann_sums_in_sum_notation.jpg]]

** Definite Integral as the Limit of a Riemann Sum

[[./img/definite_integral_as_limit_of_riemann_sum.jpg]]

** Definite Integral Properties

Midpoint:
if a <= b <= c, then:

\int_{a}^{b} dx = \int_{a}^{c} dx + \int_{c}^{b} dx

Zero-length interval:

\int_{a}^{a} dx = 0

Reverse interval (switching bounds):

\int_{a}^{b} f(x) dx = \lim_{n\to \inf} \sum_{i=0}^{n} f(x_i) \delta x, where \delta x = b - a / n


\int_{b}^{a} f(x) dx = \lim_{n\to \inf} \sum_{i=0}^{n} f(x_i) \delta x, where \delta x = a - b / n

= - \int_{a}^{b} f(x) dx

[[./img/switching_bounds.jpg]]


Sum/Difference:

y = f(x) + g(x)

\int_{a}^{b} (f(x) + g(x)) dx

\int_{0}^{1} (x^2 + sin(x)) dx = \int_{0}^{1} x^2 dx + \int_{0}^{1} sin(x) dx

[[./img/integrating_sums_of_functions.jpg]]


Constant multiple:

y = f(x)

y = s * f(x)

\int_{a}^{b} s * f(x) dx = s * \int_{a}^{b} f(x) dx

[[./img/integrating_scaled_function.jpg]]

** Functions defined by Integrals

G(x) = \int_{-3}^{x} g(t) dt

G(4) = \int_{-3}^{4} g(t) dt

G(8) = \int_{-3}^{8} g(t) dt

* Antiderivatives and Fundamential Theorem of Calculus

** Antiderivatives

derivative:

d/dx[x^{2}] = 2x

d/dx[x^{2} + 1] = 2x

d/dx[x^{2} + \pi] = 2x

antiderivative:
What is 2x the derivative of?

x^{2}, x^{2} + 1, x^{2} + \pi, x^{2} + "some constant term"

notation:

\int 2x dx = x^{2} + a

(the indefinite integral of 2x == the antiderivative of 2x)

** Fundamential Theorem of Calculus

"One should never try to prove anything that is not almost obvious"
- Alexader Grothendieck

integrals are an inverse of derivatives. If you take the derivative of
the Anti-derivative you get the function. The theorem connects
diferential and integral calculus.

first part:

[[./img/fundamental_theorem_of_calculus.jpg]]

second part:

[[./img/fundamental_theorem_of_calculus_second_part.jpg]]



** Indefinite Integral


** Improper Integral

Improper integrals are definite integrals that cover an unbounded area.
- one of the end points is unbounded

\int_{1}^{\inf} 1/x^{2} dx = \lim_{b\to\inf}\int_{1}^{b} 1/x^{2} dx

- endpoints are finite, but the integrated function is undounded

\int_{0}_{1} 1/sqrt{x} dx = \lim_{a\to 0+}\int_{a}_{1} 1/sqrt{x} dx

When our unbound area is finite, that is there exists such a limit
we say the integrak is convergent, else it is divergent.

So when a bound is \inf use limits:

Example:

\int_{1}^{\inf} 1/x^{2} dx

= \lim_{n\to\inf} \int_{1}^{n} 1/x^{2} dx

= \lim_{n\to\inf}[-1/x] = \lim_{n\to\inf} [1-1/n] = 1

In this case we say that the integral is convergent.



What if both bounds are \inf?

Example:

\int_{-\inf}^{\inf} 250/(25+x^{2})

= \int_{-\inf}^{0} f(x) dx + \int_{0}^{\inf} f(x) dx

= \lim_{n\to -\inf}\int_{n}^{0} f(x) dx + \lim_{m\to\inf}\int_{0}^{m} f(x) dx

= 50\pi (with trig substitution)



Divergent improper integral:

Example:

y = 1/x

\int_{1}^{\inf} 1/x dx = \lim_{n\ti\inf}\int_{1}^{n} 1/x dx

= \lim_{n\to\inf} ln(|x|) = \lim_{n\to\inf} ln(n) - ln(1) = \lim_{n\to\inf} ln(n) = \inf

This integral is divergent.



*** Reverse Power Rule

\int x^{n} dx = \frac{x^{n+1}}{n+1} + C iff n != -1

*** Sums

\int [f(x) + g(x)] dx = \int f(x) dx + \int g(x) dx

*** Multiples (Scalars)

\int 4x^{8} = 4 * \int x^{8}

Note: sometimes is better to first rewrite

\int x^{2}(3x - 1) dx = \int 3x^{3} - x^{2} = 3x^{4}/4 - x^{3}/3 + C

*** Indefinite Integral of 1/x

\int 1/x dx = \int x^{-1} = ln(x) + C, but for x != 0 and x > 0

it is undefined for negative values or 0. We need larger domain.

\int ln|x| + C

\int a/x dx = a * ln(x)

*** Indefinite Integral of sin, cos, e

\int sin(t) dt = - cos(t) + C

\int cos(t) dt = sin(t) + C

\int e^{a} dt = e^{a} + C

\int (e^{a} + 1/a) = \int e^{a} + \int |a| + C

*** Radicals

\int sqrt[m]{x^{n}} = \int \frac{x^{(n/m + 1)}}{n/m + 1} + C

\int (sqrt[m]{x})^{n} = \int \frac{x^{(n/m + 1)}}{n/m + 1}

*** Inverse Trig Functions

\int \frac{1}{sqrt(a^{2} - x^{2})} dx = arcsin(x/a) + C

\int \frac{1}{a^{2} + x^{2}} dx = 1/a arctan(x/a) + C

** Finding Definite Integrals

*** Reverse Power rule

\int_{-3}^{5} 4 dx = F(5) - F(-3) = 4*5 - (4 * -3) = 22

F'(x) = 4x


** u-substitution

basically it is unwinding the chain rule. A trick to ease the transforamtions.

\int (3x^{2} + 2x)e^{(x^{3} + x^{2})} dx

u = x^{3} + x^{2}

dx du/dx = (3x^{3} + 2x) dx

= \int e^{u} du = e^{u} + c = e^{(x^{3} + x^{2})} + c


Example:
[[./img/u-subtitution_mult_by_constatnt.jpg ]]

Defining u:

d/dx[ f(g(x)) ] = f'(g(x)) * g'(x)

[[./img/u-substitution_logarithmic_function.jpg]]

u-substitution: two ways to account for the limits of definite integrals

[[./img/u-substitution_definite_integrals.jpg]]



* Differential Equations

** Intro

Differential equations are very useful for modeling and simulating phenomena
and understanding how they operate.

y'' + 2y' = 3y

f''(x) + 2f'(x) = 3f(x)

d^{2}y/dx^{2} + 2 * dy/dx = 3y

The solution to differential equation is a function, or a class of functions.
Not just a value or a set of values.

Example: A particle moves along a straight line. Its speed is inversely
proportional to the square of the distance, S it has traveled.

S = distance, dS/dt = Speed

dS/dt = k/S^{2}, which is a differential equation






** Separable equations

We have the equation:

dy/dx = -x/ye^{x}^{2}

We need a solution that goes through the point (0,1)
Hint: separate the ys and dys on one hand and integrate





* Series

** Infinite sequences

** Partial Sums


Example: Finding formula for nth member of a sequence.
The nth partial sum of the series \sum_{n=1}^{\inf}
is given by S_n = n + 1 / n + 10 Write a rule for a_n.

a_{1} + a_{2} + a_{3} + ... + a_{n-1} + a_{n}

S_{n-1} = n - 1 + 1 / n - 1 + 10 = n/n+9 

a_{n} = S_{n} - S_{n-1} = n+1/n+10 - n/n+9

simplified to: 9/(n+9)(n+10)


Example: Finding member of a sequence with given partial sum formula.
The nth partial sum of the series \sigma_{n=1}^{\inf} a_{n}
is given by S_{n} = n^2+1/n+1. What is a_{7}.

a_{7} = S_{7} - S_{6}

The 7th member = sum to the 7th - sum to the 6th


Infinite Series as a limit to partial sums:

Given an infinite series S and formula for a partial sum S_n does the
series converge or diverge?

S = \sigma_{n=1}^{\inf} = a_{1} + a_{2} + ...

S_{n} = 2n^{3} / (n+1)(n+2)

The sum S can be expressed as the limit as n approaches \inf of the
partial sum. Imagine a sequence of partial sums.

S = \lim_{n\to\inf} S_{n}

\lim_{n\to\inf} 2n^{3}/(n+1)(n+2) = \frac{2n}{1 + 3/n + 2/n^{2}}

The nominator is going to grow to \inf while the denominator to 1.
The series will diverge.



* Multivariable Calculus

** Thinking about Multivariable Functions

f(x) = x^{2}

f(x, y) = x^{2} + y

Output can be a vector. You can think of it as a point in space.
f(x, y) = [3x 2y]

These functions can be visualized in just 2 dimentions, where we
visualize the entire input space in associated color with each point.

If we have f(x, y) = x^{2} ... , the color tells us the size of the
output, and the lines, called contour lines, tell us which inputs
all share a constant output value.

[[./img/contour_plot.jpg]]

Surfaces in 3d space are mapping 2d input that moves into 3d
(Parametric surfaces).

[[./img/surfaces_in3d_space.jpg]]

[[./img/mapping0.jpg]]

[[./img/mapping1.jpg]]

Vector field is where every input point is associated with some kind
of vector which is the output of the function there.

In this case 2d input to 2d vector.

[[./img/vector_field.jpg]]

And also understanding functions as transformations of space is a
great way to connect multivariable calculus with linear algebra.

There is a huge value in analogy between 2d and 3d, beacause as soon as
you start to compare 2d and 3d, you start to see patterns for how it
could extend to other dimensions that you can't neccessarily visualize.

Every point in 2d space can be given a pair of numbers like (1, 3) that
serve as instructions. Also you can think of the reverse. Every time
that you have a pair of things you know that you should be thinking 2d.
In 3d there is a similar dichotomy between triplets of things and
points in 3d space. Same thing for vectors.

3d graphs:

f(x) = x^{2}
output is parabola

f(x, y) = x^{2} + y^{2}
inputs live on tha x, y plane
output is a surface that look like 3d parabola

if we modify the function to:
f(x, y) = 1/2(x^{2}+ y^{2})
the hight of every poit will be cut in half

Interpreting graphs with slices:

f(x, y) = cos(x)sin(y)

the graph is a bumpy 3d wave like surface.
If will take x = 0 we have a slice with a plane that sits on the x origin
If we cut the graph along that plane and draw a line over that spot
we get a line that looks like the sinosuidal wave.

If x = 0:
f(0, y) = cos(0)sin(y) = 1*sin(y)
and we are left only with the sin(y) function

If y = 0:
f(x, 0) = cos(y) * sin(0) = 0
everything looks like a constant function at 0, just a line along the x.

If y = \pi / 2
f(x, \pi/2) = cos(x)sin(\pi/2) = cos(x) * 1
looks like the graph of cos(x)

[[./img/slice0.jpg]]
[[./img/slice1.jpg]]
[[./img/slice2.jpg]]

Contour plots:

The idea is that we take a nd graph slice it with planes that are all
parallel to the x, y plane and represent values of z like:
z = -1, z = -2, z = 0, z = 1, z = 2
Now we draw the lines where this planes touch the surface of the graph
and squish them down flat on to the x, y plane. Now we have something
2d that still represents some of the outputs of our function.

Small step between lines means steepness, larger distances between lines
are much more shallow.

In the coloring warmer colors are high values while cooler colors are
lower values.

Parametric curves:

Consider: f(t) = [tcos(t) tsin(t)]
1 parameter functions that output 2d vector
parameter is fancy for input

f(0) = [0 0]
f(\pi/2) = [0 \pi/2]

We get a spiral pattern.

Parametric surfaces:

f(t,s) = [3cos(t) + cos(t)cos(t), 3sin(t) + sin(t)cos(t), sin(s)]

2d input to 3d output

f(0, \pi) = [2, 0, 0]

Suppose ew keep s to be a constant value and let t vary freely.
In this case we get a circle surface on the x, y.

If we do the opposite and keep just t a constant, we get another
circle surface on the z axis.

If we let them both run freely we get the z axis circle to becaome a 3d
surface circumventing the x, y surface. End result is a torus(doughnut).

Vector fields:

come up all the time in physics, fluid flow, electrodynamics.
It is a way of visualizing a functions that have the same number of
dimentions in their input as in their outpus.

f(x, y) = [y^{3} - 9y, x^{3} - 9x]

You have 2d in the input and 2d in the output so it must 4d
visualization. Instead what we do , we look only in the input space.
Only in the x, y plane. For each individual input point (like (1,2))
we are going to consider the vector that it outputs and attach that
vector to the point.

f(1,2) = [-10 -8]

We scale down the resulting vectors. Color may hint length of the vectors
where warm is long and cold is shorter.

You can describe flow of liquids with vector fields. The speed and
direction of a particle are described by the vector it is crossing
over.

Keeping the density coresponds to the concept of divergence.



** Derivatives of Multi-variable functions

*** Partial derivatives

f(x) = x^{2}
df/dx(2) = 2*2^{1}


f(x,y) = x^{2} y + sin(y)

NOTE: Notetion gets really confusing due the too many options available
most of them verbose and counter intuitive.

df/dx(x, y)
uses now the del simbol:
\partial f / \partial x(x, y)

also (with physics package):
\pdv f/ \pdv y(x, y)

f_{y}'(x) = f_{x} = df/dx



Computing the partial derivative at a point:

df/dx(1,2) and df/dy(1,2)

df/dx(1,2) = x^{2} * 2 + sin(2) | at x=1

= 4x + 0 = 4

df/dy(1,2) = 1^{2} * y + sin(y) | at y=2

= y + cos(y)


Graphical understanding of the partial derivatives:

f(x,y) = x^{2} y + sin(y)

df/dx(-1,1) = 2xy = -2*-1*1 = -2
df/dy(-1,1) = x^{2} + cos(y) = 1+0.9998... ~ 2

Treating y as a constant is basically like slicing the whole graph with a
plane that represents the constant y value. Sliding the plane along the
y axis represents the various y values.
In our example function if we cut the graph at that plane and draw the
line we get all the points on the graph where y = 1.

[[./img/graphical_partial_f_of_xy.jpg]]
[[./img/graphical_partial_dfdx.jpg]]
[[./img/graphical_partial_dfdy.jpg]]

Formal definition:

\frac{\partial f}{\partial y}(a,b)= \lim_{h\to 0} \frac{f(a, b+h)}{h} - f(a, b)

Symetry of second partial derivatives:

Schwarz's theorem if the second partial derivatives are
continuous at the relevant point than f_{xy} = f_{yx}.

f(x,y) = sin(x)y^{2}

f_x = cos(x)y^{2}
f_y= sin(x)2y

f_xx = -sin(x)y^{2}
f_xy = cos(x)2y
f_yx = cos(x)2y
f_yy = 2sin(x)

*** Gradient and partial derivatives

Gradient:

\nabla f = [f_{x} f_{y}]
\nabla f = [df/dx df/dy]

You can think of it as the full derivative, because it combines the
partial derivatives in a vector.

This function that outputs a vector can nicely be visualized with a vector
field. 

f(x, y) = x^{2} + y^{2}

\nabla f(x, y) =[2x 2y]

The output can be represented with a vectors pointing away from the
origin. The reason for that is if you have any given input point (x, y)
then the vector that that input point represents is [x, y], but the ouput
vector is [2x 2y], 2 times bigger(we attach the output vector to the tip
of the input vector, it has the same direction, but is twice as long).

We can use this gradient field to tell the direction of steepest ascent.
The length of the gradient vector tells you the steepness of the direction
of steepest ascent. In this case alway from the origin.

[[./img/gradient_graphs1.jpg]]
[[./img/gradient_graphs2.jpg]]
[[./img/gradient_graphs3.jpg]]

Gradient and Contour maps:

f(x,y) = xy


If the vector is crossing a contour line, it's perpendicular to that
contour line.
Lets zoom in on a region and draw the contour lines for f=2 and f=2.1.
We know that the vector points in the direction of steepest ascent.
If we imagine all the possible vectors at that point the quastion 

Gradient is always perpendicular to gradient lines.

[[./img/gradient_contour_maps.jpg]]

Directional derivative:

f(x,y) = x^{2} * y

v = [-1; 2]
w = [a; b]

The directional derivative uses a vector to represent the small nudges
in x and y directions. The small nudge is h that is approaching 0.

hv = [-h; 2h]

\nabla_v f(i\vec{a}) = \lim_{h\to 0} \frac{f(\vec{a} + h\vec{v}) -
f(\vec{a})}{h}


When you take a small nudge in the direction of that vector, what is
the resulting change to the output?

The formula for computing the directional derivative is:

\nabla_v f(x,y) = df/dv = \partial_{v} = a(df/dx) + b(df/dy)
= [a; b] . [df/dx; df/dy] = w . \nabla f

The last one is more flexible for many dimentions that are contained in
the vector w.

\nabla_{v} f(x,y) = [-1; 2].[df/dx; df/dy] = -1(df/dx) + 2(df/dy)

NOTE: the directional derivative is the dot product of the directional
vector and the gradient. The directional vector contains the scalars
for the nudges in all the dimentions. The gradient is the vector with
all the partial derivatives for all dimentions.

NOTE: use the unit vector (absolute value) when you think of slope
to normalize: frac{\nabla f . v}{||\vec(v)||}
When you are moving in the direction of the gradient, the rate at which the
function changes is given by the magnitude of the gradient.


*** Differentiating parametric curves

Vector-valued functions intro:

We are given the curve C: x = x(t), y = y(t), a <= t <= b
We are describing a curve using 2 parametric equations.

Vector-valued functions are in some ways a replacement for traditional
parameterization to describe a curve.


\vec{r}(t) is a position vector = x(t)*\hat{i} + y(t)*\hat{j}

\vec{r}(a) = x(a)*\hat{i} + y(a)*\hat{j}

[[./img/vector-valued_functions_intro.jpg]]

Vector-valued function differetiation:

\vec{r}(t) = x(t)*\hat{i} + y(t)*\hat{j}, a <= t <= b (a curve between a and b)

[d/dx; d/dy] \vec{r}(t) = 

TODO: finish vector valued functions

** Multivariable Chain Rule

f(x,y) = x^{2} * y

x(t) = cos(t)

y(t) = sin(t)

f(x(t), y(t))

You can think of t as just living on a number line, then x and y which
is just a plane, and then you have the output the value of f.
This composition of functions is taking a single point on t and moving it
over to 2d space and then from there, our multivariable function takes
that back down to 1d. It seems in this case we can treat it as a single
variable function and apply the regular product and chain rule.

d/dx f(cos(t), sin(t)) = (cos(t))^{2} * sin(t)
= (cos(t))^{2} * cos(t) + 2cos(t)sin(t) * -sin(t)
= F_{y} * dy/dt + F_{x} * dx/dt

F_{y} = 2xy
F_{x} = x^{2}
dx/dt = -sin(t)
dy/dt = cos(t)

[[./img/multivariable_chain_rule_simple.jpg]]

It becomes simpler if we take f as a vector valued function.
It is a dot product between the vector containing the partial derivatives
and the vector containing the ordinary derivatives. And they are both
special vectors. The gradiaent of f and the right one is the derivative
of v with respect to t.

\vec{v}(t) = [ x(t); y(t) ]

dv/dt = [ dx/dt ; dy/dt ]

F_{x}*dx/dt + F_{y}*dy/dt = [ F_{x}; F_{y} ] . [ dx/dt; dy/dt ] = \nable f . \vec{v}'(t)

And the more formal rule is:

\nabla f(\vec{v}(t)).\vec(v)'(t)

** Curvarture

Intuition:

Think of steering wheel, path curvarture and turning radius of a car.
The turning radius will be very big with slightly turned steering wheel
and the curvarture will be very small.

\Kapa = Radius of curvarture

\Kapa = 1 / R 

\||T_{i}|| = the unit tangent vector
s = arc lenght

The Unit tangent vector changes rapidly with high curves.

- The radius of a curvarture at a point is loosly speaking the radius of a
circle which fits the curve most snugly at that point.

- the curvarture, denoted \kapa, is 1 / the radius of the curvarture.

- in formulas curvarture is defined as the magnitude of the derivative of
a unit tangent vector function with respect to arc length

\kapa = \|| dT/ds \||

- the unit tangent vector tells you which direction you are moving, and
the rate at which it changes with respect to small steps ds along the
curve is a good indication of how quickly you are turning.

[[./img/curvarture.png]]

Let \vec{S}(t) be a function that defines a curve in the xy-plane.

\vec{S}(t) = [ x(t); y(t)]

\vec{s}(t) = [t - sin(t); 1 - cos(t)];

is the same as the parametric equation:

x(t) = t - sin(t)

y(t) = 1 - cos(t)

Computing curvarture:

- step 1: Find a unit tangent vector

define a vector-valued function T(t), which takes in the same parameter and
returns a unit vector which is tangent to the curve at the point \vec{s}(t).

- step 2: Find dT/ds

\||dT/ds\|| = \||dT/dt\|| / \||d\vec{s}/dt\|| 




** Curl

Intuition:

Again think of the vector field as a liquid, with molecules moving along //
the vector they are attached to at that point. In our example you may //
start to notice regions where a counterclockwise rotation is forming, //
here the curl is positive. Whereas, if it is clockwise rotation the curl //
is negative. If there is no specific rotation, some points come from the //
top right others from the bottom left, but there is no net rotation, //
those are regions with 0 curl.

2d curl formula:

\vec{v}(x, y) = [P(x, y); Q(x, y)]

2d-Curl \vec{v} (x, y) > 0

\partial P / \partial y < 0

\partial Q / \partial x > 0

[[./img/2d_curl0.png]]

so the more it looks like the described above perfect setting the more
the value of the 2d-curl in the formula below is positive:

2d-curl \vec{v}(x, y) = \partial Q / \partial x -  \partial P / \partial y 

Computing from the formula:

\vec{v}(x, y) = [P(x, y); Q(x, y)] = [y^{3} - 9y; x^{3} - 9x]

2d-curl \vec{v}(x, y) = 3x^{2} - 9 - (3y^{2} - 9)

if x = 3, y = 0

= 27 - 9 - 9 = 27

which is a positive number and we have a counter-clockwise rotation


** Laplacian (la-pla-si-an)

An operator in the same way that the divergence, the gradient, or the
curl, or even just the derivative are operators. Things that take a
function and give you another function. 

f(x, y)

\bigtriangleup f(x,y) = \nabla . \nabla f

use this big triangle up symbol for notation.

It is like second derivative, because the way it is defined is you take
the divergence of the gradient of f.

div(grad f)

\nabla . \nabla f

take the vector field that represents the gradient. Think of it as a
fluid in which the vectors point the derection of movement. These
vectors point in the direction of steepest ascend and the places
where they group are maxima. The places where they diverge from are
valleys, minima. So low divergence mean maximum point, high divergence
mean minimum point. 

So this Laplasian operator is like a measure how mush of a minimum is
this (x, y) point.

Analogius to the  second derivate when it is positive it is minimum.

Computation:

First find the gradient then multiply by the function

f(x, y) = 3 + cos(x/2) * sin(y/2)

[d/dx; d/dy] . f[df/dx; df/dy] = [d/dx; d/dy] . [1/2(-sin(x/2))*sin(y/2); cos(x/2)*1/2*cos(y) ] 

= (1/2 * 1/2 * -cos(x/2) * sin(y/2)) + (1/2 * 1/2 * -sin(y/2) * cos(x/2))

That is the divergence of the gradient field.

Explicit Laplacian Formula:

f(x_{1}, x_{2}, ..., x_{n})

\bigtriangleup f = [\partial / \partial x_{1}, ... , \partial / \partial x_{n}] .
[\partial f / \partialx_{1}, ..., \partial f / \partial x_{1}] =
\sum_{j=1}^{n} \partial/\partial x_{j} * \partial f/ \partial x_{j} = 
\sum_{j=1}^{n} \partial^{2}f / \partial x_{j}^{2}

Harmonic functions:

A Harmonic function is a one where the Laplacian is equal to 0.

\bigtriangleup f(x,y) = \nabla . \nabla f(x, y) = 0

So it must have second derivative = 0

f''(x) = 0,

and if we integrate:

f'(x) = c

f(x) = cx + k

we get a linear function.


** Jacobian

Jacobian matrix:

[2 -3; 1 1] [x; y] = [2x + (-3)y; 1x + 1y]

Linear transformation:

[1; 0], [0; 1]

[2 -3; 1 1] [1; 0] = [2 + 0; 1 + 0] = [2; 1]

[2 -3; 1 1] [0; 1] = [0 + (-3); 0 + 1] = [-3; 1]; 

grean vector lands at (2,1), and that corresponds very directly with the
fact that the first column of the matrix is [2;1] and similarly the red
vector lands at the coordinates [-3; 1], which is the second column.

[[./img/linear_transformation1.png]]
[[./img/linear_transformation2.png]]

A transformation is linear if it satisfies the properties:

+ L(a * \vec{v}) = a * L(\vec{v})

(the lin tran of scalar * vector must = scalar * lin tran of the vector)

+ L(\vec{v} + \vec{w}) = L(\vec{v}) + L(\vec{w})

+ L([x; y]) = L(x * [1; 0] + y * [0; 1])

x * L([1; 0]) + y * L([0; 1])

after the transformation the point (2,1) ends up at (1; 3)
that is the vector [2 ihat; 1 jhat] ends up still being [2 ihat; 1 jhat]
The basis vectors keep their relation linear after the trnsformation.

Local linearity for a multivariable function:

A lot of the concepts in multi-variable calculus are all about ideas
originally from lenear algebra and transferring those to apply to
nonlinear problems.

f([x; y]) = [x + sin(y); y + sin(y)]

when we apply the transformation it gets really wavy and curly, this is
not at all a linear transformation. You must store not just 4 numbers
but a lot more information to know where everything goes.

But lets simplify it and just look at the point

[\pi/2; 0] = [\pi/2 + sin(0); \pi/2 + sin(\pi/2)] = [\pi/2; 1] ~ [1.57; 1]

[[./img/nonlinear_transformation0.png]]

so the point moves just 1 unit up.
But this function has a nice property called local linearity.
If we zoom down enough the grid around the point starts to
look more like linear. Zoomed enough it approximates linear 
transformation. Same as with slopes and derivatives.

[[./img/local_linearity_multii-variable_calculus.png]]

The Jacobian matrix:

we are zooming at the point (-2, 1)

[\partialf_{1}/\partialx   \partialf_{1}/\partialy;
 \partialf_{2}/\partialx   \partialf_{2}/\partialy]

don't take the function, evaluate it at that point. When you evaluate
each of the partial derivatives at that point you a 2x2 matrix that is
going to represent the linear transformation that this location looks
like ones you have zoomed in. This matrix is called the Jacobian matirix.
It is fundamentally supposed to represent what a transformation looks
like when you zoom in near a specific point.

Computing the Jacobian matrix:

f([x; y]) = [x + sin(y); y + sin(y)]

at point (-2, 1)

[\partial f_{1}/\partial x   \partial f_{1}/\partial y;
 \partial f_{2}/\partial x   \partial f_{2}/\partial y]

compute the partial derivatives and plug in the values:

[1 cos(y); cos(x) 1] = [1 cos(1); cos(-2) 1] = [1 0.54;-0.42 1]

The Jacobian determinant:

det([3 1; 0 2]) = 3*2 - 1*0 = 6

You compute it by the diagonals, but there is a geometric intuition.
You can think of the determinant as a measure of how much this
transformation streches or squishes space. How the unit square(the one
composed by the unit vectors) gets stretched out.

By factor of 6 in our example.

[[./img/determinant0.png]]
[[./img/determinant1.png]]


det([1 cos(y); cos(x) 1]) = 1 * 1 - cos(y) * cos(x) = 1 - (cos(-2) * cos(1))
= 1 - (-0.42 * 0.54) = 1 + 0.227 = 1.227

The are tend to get stretched by factor of 1.227 around the point (-2,1)

"A way to think of multi dimentional space as linear space with
certain approximations and keeping the factor of change the determinant"



* Pre Calculus

# Trigonometry
# Linear Algebra


* Trigonometry
** Radians

Degrees seem to be historic artefact(coinsidance)
Radians are more rational(neutral, universal)

1 radian = 1 part of the circle with length equal to the radius
1 radian = 1 radius

How many radians in a 360deg(circle)?

c = 2πr
360 deg = c / r = 2πr / r = 2π radians
180 deg = π radians
1 deg   = π / 180
1 radian = 180 / π

** Unit circle definitions of sin and cos

  Unit circle - a circle with radius

[[./img/unit_circle.jpg]]

  We have a right angled triangle between the x and radius
  Theta is the angle between the x and radius

  soh cah toa - works well with triangles where the angle is
  less than 90 deg, but breaks on the circle

  sin Theta = Opposite/Hypotenuse = a / 1 = a

  cos Theta = Opposite/Hypotenuse = b / 1 = b

  The point (a,b) on the circle gives us the sin and cos of Theta


  tangens, cosecant, secant and cotangent:

  tan T = sin T / cos T = opposite / adjacent

  csc T = 1 / sin T = hypotenuse / opposite = h / a

  sec T = 1 / cos T = hypothenuse / adjacent = h / b

  cot T = 1 / tan A = adjacent / opposite = b / a

  Some specieal values:

  sin 0  = 0
  sin 30 = 1/2
  sin 45 = sqrt(2)/2
  sin 60 = sqrt(3)/2
  sin 90 = 1

|   T  | sin T | cos T |
|------+-------+-------|
|  0   |   0   |   1   |
| π/2  |   1   |   0   |
|  π   |   0   |  -1   |
| 3π/2 |  -1   |   0   |
|  2π  |   0   |   1   |

  Pytagorean identity

  cos^2(T) + sin^2(T) = 1

  Double angle identities:

  sin(2x) = 2 * sin(x) * cos(x)
  cos(2x) = cos^{2}(x) - sin^{2}(x)
          = 2 cos^{2}(x) - 1
          = 1 - 2sin^{2}(x)

  tan(2x) = 2tan(x) / 1 - tan^{2}(x)

  Power reducing identities:

  sin^{2}(x) = (1 - cos(2x)) / 2
  cos^{2}(x) = (1 + cos(2x)) / 2
  tan^{2}(x) = (1 - cos(2x)) / (1 + cos(2x))



  [[./img/sine_cosine_identities_symmetry.jpg]]

*** Features of sinusoidal functions

    - midlane:

    - amplitude:
      how far does the function vary from the midline

    - period:
      how much to change x to go to the same point in the cycle

*** Tau or Pi

 π = c / d = c / 2r

 Eulers formula:

 e^{i}T = cos(T) + sin(T)

 Eulers identity:

 e^{i} \pi + 1 = 0

 Tau = c / r = 2\pi = 6.283185...

 C = \tau * r

 π/2 = \tau/4 radians

 e^{i}\tau = cos(\tau) + i * sin(\tau) = 1 + 0 = 1

** Inverce Trig functions

sin^{-1}(x) , arcsin is defined as sin(y) = x

tan^{-1}(x) , arcsin is defined as tan(y) = x


| \theta    | sin(\theta)                      | cos(\theta)                      | tan(\theta)                      |
|-----------+----------------------------------+----------------------------------+----------------------------------|
| arcsin(x) | sin(arcsin(x)) = x               | cos(arcsin(x)) = sqrt(1-x^2)     | tan(arcsin(x)) = x / sqrt(1-x^2) |
| arctan(x) | sin(arctan(x)) = x / sqrt(1+x^2) | cos(arctan(x)) = 1 / sqrt(1+x^2) | tan(arctan(x) = x                |

d/dx arcsin(x) = 1 / sqrt(1-x^{2})

d/dx arccos(x) = - 1 / sqrt(1-x^{2})

d/dx arctan(x) = 1 / 1 + x^{2}

d/dx arcot(x) = - 1 / 1 + x^{2}

** Hyperbolic Trig functions

cosh x = e^{x} + e^{-x} / 2

sinh x = e^{x} - e^{-x} / 2

NOTE: read as [kosch] and [sinch]


* Algebra

** Properties of exponents

x^{n} * x^{m} = x^{n+m}

x^{n}/x^{m}   = x^{n-m}

(x^{n})^{m}   = x^{n*m}

(x * y)^{n} = x^{n} * y^{n}

(x/y)^{n}   = x^{n}/y^{n}

1/(x^{n})   = 1 * x^{-n}

x^{(3/4)}   = x^{(1/4)}^{3}

\sqrt[3]{x} = x^{1/3}

** Properties of logarithms

ln a/b = ln a - ln b
