** Sorting (Insertion Sort, Merge Sort)

*** Why?

Many problems like searching become easy when items are sorted.

- Finding a medien for example:

unsorted array A[0:n] -> sorted array B[0:n]

B[n/2] = medien

- Binary Search:

if A[0:n] is sorted we are lookig for specific item k in log time

The simplest paradigm for Divide and Conquer

- Data compression:

sort items and automatically find the duplicates to eliminate

- Computer Graphics

You want to render front to back, so you need items sorted
Sometimes (to account for transperancy) you need it sorted back to front

*** Insertion Sort

For i = 1, 2, \dots, n
insert A[i] into sorted array A[0:i-1]
by pairwise swaps down to the correct possition

[5,2,4,6,1,3] -> [2,5,4,6,1,3] -> [2,4,5,6,1,3] -> [2,4,5,6,1,3]
-> [1,2,4,5,6,3] -> [1,2,3,4,5,6]

5 is first so it is sorted, we start from 2 where is the key.
The key moves left to rigth and swaps.

\Theta (n) steps (key positions)
Each step is \Theta (n) compares and swaps
But if you are comparing entities and not numbers, the swap function migth
be more complex and require more steps.

In case Compares are more expensive than Swaps we have:
\Theta (n^2) compares cost

If we replace pairwise swaps with binary search we get \Theat (n log n)

*** Merge Sort

Divide and Conquer, recursive algorithm

A -> split to -> L and R -> sort -> L' and R' -> merge -> to sorted A'

[[./img/6006/merge_sort.jpg]]

size n -> 2 unsorted size n/2 -> 2 sorted size n/2 -> size n


Merge: assumes two sorted arrays as input

L' = [20,13,7,2] and R' = [12,11,9,1]

Think of it as a two finger algorithm:
Start at one end and compare 2 elements from L' and R'
Move the smallest to the sorted array. Repeat.

>> compare 1 and 2
>> move 1 to sorted array
>> compare 2 and 9
>> move 2 to sorted array
>> compare 7 and 9
>> move 7 to sorted array
>> \dots

[[./img/6006/merge_routine.jpg]]

The merge routine does most of the job and is \Theta (n)
The overall complexity of the algorithm is \Theta (n log n)

Thm.: Merge sort is \Theta (n log n)

Proof: 

By looking at the merge routine we can construct a recurrence that looks
like this.
Complexity: T(n) = C_{1} + 2T(n/2) + C * n,

where C_{1} is the divide step, 2T(n/2) is the recursive part, and C*n is
the merge part 

C*n -> C*n/2 C*n/2 -> C*n/4 C*n/4 C*n/4 C*n/4 -> \dots -> C \dots C

the number of levels is 1+log(n), the number of leaves is n
and you're doing the same amount of work C*n at each level:

T(n) = C*n * (1 + log(n)) = \Theta (n * log n)

[[./img/6006/merge_sort_complexity.jpg]]

Merge sort needs \Theta (n) auxilary space for (L,R) and (L',R'),
Insertion sort (in place sort) needs \Theta (1) auxilary space
Consider this if you need to sort like billion of items.
There is an advanced in place merge sort algorithm, but is inpractical
with its worse running time.

In python:

Merge sort is: 2.2 * n * log(n) ms
Insertion sort is: 0.2 * n^{2} ms 

In C:
Insertion Sort is: 0.01 * n^{2} ms  


*** Recurrencies

T(n) = 2T(n/2) + C*n^{2}

C*n^{2} -> C*n^{2}/4 + C*n^{2}/4 
-> C*n^{2}/16 + C*n^{2}/16 + C*n^{2}/16 + C*n^{2}/16

1+log(n) levels, n leaves,

work at leval 1: C*n^{2}
work at leval 2: C*n^{2}/2
work at leval 3: C*n^{2}/4
\dots
work at leval 1+log(n): C*n

top level C*n^{2} dominates, complexity is \Theta (n^{2})

T(n) = 2T(n/2) + \Theta (1) or C

C -> C + C -> C + C + C + C -> \dots -> n * C

work at leval 1: C
work at leval 2: 2C
work at leval 3: 4C
\dots
work at leval 1+log(n): nC

the bottom level n * C dominates, complexity is \Theta (n)

** Heaps and Heap Sort

Heap as example implementaion of priority queue, and base for sorting algorithm
known as Heap Sort.

*** Priority Queue

Implements a set S of elements, each of elements associated with a key.
Operations: pick max or min, delete, insert, change

insert(S, x)   : insert element x into set S

max(S)         : return element of S with a largest key

extract_max(S) : as max(s), but also removes it from S

increase_key(S,x,k) : increase the value of x's key to k

*** Heap
 
An array visualized as a nearly complete binary tree.

[16, 14, 10, 8, 7, 9, 3, 2, 4, 1]

10 elements is not 15, so it is not a full binary tree
index 1 is the root of the tree, 2 and 3 are the children of 1

- Heap as a tree:

root of  tree: 1st element (i=1)

parent(i) = i/2

left(i) = 2i, right(i) = 2i + 1

A Heap must keep the Heap property correct:
- Max-Heap property: the key of a node is >= the key of its children
- Min-Heap property: the key of a node is <= the key of its children

Heap operations:

build_max_heap : produces the max heap from an unordered array

max_heapify(A, i) : correct a single violation of the heap property in
                    a subtree' s root


Given the asumption that the trees rooted at left(i) and right(i) are
max-heaps the complexity of the max_heapify is bound by the heigth of
the tree and the tree is nearly balanced binary tree => \Theta (\log n)

[[./img/6006/min_heap.jpg]]
